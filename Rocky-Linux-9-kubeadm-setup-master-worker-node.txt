------------------------------------------------------------------------------
steps to creating kubeadm master slave setup on the CentOS Stream release 9 
-----------------------------------------------------------------------------

1. Prerequisites
System Requirements:

At least 2 CPUs and 2GB RAM per node.
10GB of disk space.
Connectivity between all nodes.
Prepare Nodes:

Install CentOS Stream 9 on each node.
Ensure each node has a unique hostname and is reachable via hostname or IP.

---------------------------------------------------
Action performed on both Master and worker node [Run all these command with root priveleges]
---------------------------------------------------
1. Update System:
sudo dnf update -y

2. Disable SELinux:
setenforce 0
sed -i 's/^SELINUX=enforcing$/SELINUX=permissive/' /etc/selinux/config

3.Disable Swap:
sudo swapoff -a
sudo sed -i '/swap/d' /etc/fstab

4.Enable Bridging for Networking:
cat <<EOF | sudo tee /etc/modules-load.d/k8s.conf
overlay
br_netfilter
EOF

sudo modprobe overlay
sudo modprobe br_netfilter
sudo dnf install -y yum-utils
sudo yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo
sudo dnf install -y docker-ce docker-ce-cli containerd.io
sudo systemctl enable --now docker


cat <<EOF | sudo tee /etc/sysctl.d/k8s.conf
net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
net.ipv4.ip_forward = 1
EOF

sudo sysctl --system

5.Disable the firewalld 
systemctl stop firewalld

6.Install Docker or CRI-O (Container Runtime)
sudo dnf install -y yum-utils
sudo yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo
sudo dnf install -y docker-ce docker-ce-cli containerd.io
sudo systemctl enable --now docker

7.Add required configuration:
cat <<EOF | sudo tee /etc/docker/daemon.json
{
  "exec-opts": ["native.cgroupdriver=systemd"],
  "log-driver": "json-file",
  "log-opts": {
    "max-size": "100m"
  },
  "storage-driver": "overlay2"
}
EOF

sudo systemctl restart docker

7. Install Container Runtime 
	dnf install -y containerd

8. Configure containerd
	mkdir -p /etc/containerd
	containerd config default | sudo tee /etc/containerd/config.toml
	
9. Ensure the cgroup driver is set to systemd in /etc/containerd/config.toml. Edit the file and look for the following section:
	vi /etc/containerd/config.toml
	[plugins."io.containerd.grpc.v1.cri".containerd.runtimes.runc.options]
		SystemdCgroup = true
Note: If SystemdCgroup = false change it to the true.

10. Restart containerd:
sudo systemctl restart containerd
sudo systemctl enable containerd

11. Verify Socket File
Check if the containerd socket file exists at /var/run/containerd/containerd.sock:

ls -l /var/run/containerd/containerd.sock

12. If the file is missing, restart containerd:
systemctl restart containerd

13. Installing kubeadm, kubelet and kubectl 
https://v1-31.docs.kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/

Add the Kubernetes yum repository. The exclude parameter in the repository definition ensures that the packages related to Kubernetes are not upgraded upon running yum update as there's a special procedure that must be followed for upgrading Kubernetes. Please note that this repository have packages only for Kubernetes 1.31; for other Kubernetes minor versions, you need to change the Kubernetes minor version in the URL to match your desired minor version (you should also check that you are reading the documentation for the version of Kubernetes that you plan to install).

# This overwrites any existing configuration in /etc/yum.repos.d/kubernetes.repo
cat <<EOF | sudo tee /etc/yum.repos.d/kubernetes.repo
[kubernetes]
name=Kubernetes
baseurl=https://pkgs.k8s.io/core:/stable:/v1.31/rpm/
enabled=1
gpgcheck=1
gpgkey=https://pkgs.k8s.io/core:/stable:/v1.31/rpm/repodata/repomd.xml.key
exclude=kubelet kubeadm kubectl cri-tools kubernetes-cni
EOF


#Install kubelet, kubeadm and kubectl:

sudo yum install -y kubelet kubeadm kubectl --disableexcludes=kubernetes
(Optional) Enable the kubelet service before running kubeadm:

sudo systemctl enable --now kubelet
The kubelet is now restarting every few seconds, as it waits in a crashloop for kubeadm to tell it what to do.


13. Update kubeadm Configuration
Ensure kubeadm is aware of the container runtime. Kubernetes uses containerd as the default runtime in many setups, but you can explicitly configure it.

Create or edit the kubeadm configuration file (if required):

sudo vi /etc/default/kubelet

Add the following line if it’s not already present:
KUBELET_EXTRA_ARGS="--container-runtime=remote --container-runtime-endpoint=unix:///var/run/containerd/containerd.sock"

14. Restart the kubelet service:
sudo systemctl restart kubelet

---------------------------------
Master Node Specific actions, change the IP address 192.168.56.102 with your Master node IP address 
------------------------------
15. Run kubeadm init command from Master node.

kubeadm init \
    --apiserver-advertise-address=192.168.56.102 \
    --apiserver-cert-extra-sans=192.168.56.102 \
    --pod-network-cidr=192.168.0.0/16
	
kubeadm init --apiserver-advertise-address=10.112.39.136  --apiserver-cert-extra-sans=10.112.39.136  --pod-network-cidr=10.112.0.0/16
	
--apiserver-advertise-address: The IP address the API server listens on.
--apiserver-cert-extra-sans: Additional IPs/DNS names to include in the certificate.


After successful execution of init command it will gives the below join command .
kubeadm join 192.168.56.102:6443 --token 6t059s.8viufm3wjzf0b8uw --discovery-token-ca-cert-hash sha256:cf8a6cfa9e1207fc19d0c0690e90b6ad1d7474aa8fdcce66b043037ccc72814d --v=5

16. Reconfigure kubectl: After reinitializing, set up kubectl:
mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config

17. Install the Pod Network Add-On: Reapply the network plugin (e.g., Calico):
kubectl apply -f https://docs.projectcalico.org/manifests/calico.yaml

----------------------------------------
Worker Node Action
----------------------------------------
18. Permanently disable the firewalld
systemctl disable firewalld
systemctl stop firewalld

19. Run the join command from the worker node.
kubeadm join 192.168.56.102:6443 --token 6t059s.8viufm3wjzf0b8uw --discovery-token-ca-cert-hash sha256:cf8a6cfa9e1207fc19d0c0690e90b6ad1d7474aa8fdcce66b043037ccc72814d --v=5



This should successfully join the worker nodes.

[root@vbox ravi]# systemctl status firewalld
----------------------------------
Master NODE actions
----------------------------------

20. Permanently disable the firewalld
systemctl disable firewalld
systemctl stop firewalld

21. Check the status of firewalld
[root@vbox ravi]# systemctl status firewalld
○ firewalld.service - firewalld - dynamic firewall daemon
     Loaded: loaded (/usr/lib/systemd/system/firewalld.service; disabled; preset: enabled)
     Active: inactive (dead) since Mon 2024-12-23 22:33:53 IST; 2min 5s ago


Verify the node status and try to create a pod.

[root@vbox ravi]# kubectl get nodes
NAME     STATUS   ROLES           AGE     VERSION
vbox     Ready    control-plane   10m     v1.32.0
worker   Ready    <none>          3m24s   v1.32.0

--------------------------------
Testing of the cluster
--------------------------------
[root@vbox ravi]# kubectl create deployment nginx --image=nginx
deployment.apps/nginx created
[root@vbox ravi]# kubectl expose deployment nginx --type=NodePort --port=80
service/nginx exposed
[root@vbox ravi]# kubectl get pods -o wide
NAME                     READY   STATUS              RESTARTS   AGE   IP       NODE     NOMINATED NODE   READINESS GATES
nginx-5869d7778c-pgkjf   0/1     ContainerCreating   0          16s   <none>   worker   <none>           <none>
[root@vbox ravi]# kubectl get svc nginx
NAME    TYPE       CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE
nginx   NodePort   10.101.190.30   <none>        80:32470/TCP   26s
[root@vbox ravi]# kubectl get pods -o wide
NAME                     READY   STATUS    RESTARTS   AGE   IP               NODE     NOMINATED NODE   READINESS GATES
nginx-5869d7778c-pgkjf   1/1     Running   0          56s   192.168.171.65   worker   <none>           <none>


--------------------------
Monitoring the cluster
-----------------------
Monitor Cluster Health:

Check the status of cluster components:

kubectl get componentstatuses
View logs for any debugging:

kubectl logs -n kube-system -l k8s-app=kube-dns

[root@vbox ravi]# kubectl get componentstatuses
Warning: v1 ComponentStatus is deprecated in v1.19+
NAME                 STATUS    MESSAGE   ERROR
controller-manager   Healthy   ok
etcd-0               Healthy   ok
scheduler            Healthy   ok
[root@vbox ravi]# hostname -I
10.0.2.15 192.168.56.102 172.17.0.1 192.168.240.128 fd00::a00:27ff:fe51:6176
[root@vbox ravi]# hostname
vbox
[root@vbox ravi]#

--------------------------------------
Steps to Install the Metrics Server
Download and Install the Metrics Server: The Metrics Server is not installed by default in Kubernetes, so you need to deploy it manually.

You can install it by applying the official metrics-server manifest:
-------------------------------------------
kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml

Verify the Metrics Server is Running: After installing, check that the Metrics Server pod is running in the kube-system namespace:
kubectl get pods -n kube-system

Check Metrics: Once the Metrics Server is running, you can use the kubectl top command to view metrics for nodes or pods.

To view node metrics:
kubectl top nodes
kubectl top pod






